
import os
import math
import pickle
import re
import sys
import nltk
import os.path
from os import path
import itertools
from nltk import WordNetLemmatizer, FreqDist
from nltk.corpus import stopwords
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from nltk.tokenize import word_tokenize

from nltk.collocations import BigramCollocationFinder
from nltk.metrics import BigramAssocMeasures

# Person class =================
class Address:
    def __init__(self, year, president,orig_text,orig_tokens_length,tokens_t,most_common_25):
        self.year = year
        self.president = president
        self.orig_text = orig_text
        self.orig_tokens_length = orig_tokens_length
        self.tokens = tokens_t
        self.most_comm_tokens = most_common_25
        self.read_score =''
        self.read_rate =''
        self.sentiment =''
    def compute_readability(self):

        sents_length = len(nltk.sent_tokenize(self.orig_text))
        long_words = len([t for t in self.tokens if len(t) > 5])
        self.read_score = round((self.orig_tokens_length / sents_length + (long_words * 100) / self.orig_tokens_length), 2)
        if self.read_score < 25 :
            self.read_rate = 'Children'
        elif self.read_score < 31 :
            self.read_rate = 'Simple'
        elif self.read_score < 41 :
            self.read_rate = 'Normal'
        elif self.read_score < 51 :
            self.read_rate = 'Factual'
        elif self.read_score < 61 :
            self.read_rate = 'Technical'
        else:
            self.read_rate = 'Difficult'

        sia = SentimentIntensityAnalyzer()
        self.sentiment = sia.polarity_scores(self.orig_text)

# =============================
def text_analyzer(address_list):
    # print(pickledAddress)

    print("Main menu:\n"
          "1. See a list of Presidents\n"
          "2. Look up addresses by President\n"
          "3. Look for collocations in the inaugural corpus\n"
          "9. Quit\n")

    user_input = get_user_input()
    if user_input == '1' :
        print("Your Selected Option: See a list of Presidents\n")
        display_president_list(address_list)
        print("\n")
    elif user_input == '2' :
        print("Your Selected Option: Look up addresses by President\n")
        look_up_address(address_list)
        print("\n")
    elif user_input == '3' :
        print("Your Selected Option: Look for collocations in the inaugural corpus\n")
        look_for_collocations(address_list)
        print("\n")

def display_president_list(address_list):
    count =0
    for key, value in address_list.items():
        count+=1
        print(count,'- ', value.president)

def look_up_address(address_list):
    print("Look up addresses by President")
    flag = True
    while flag:
        prompt = input("Enter president name Or Enter 0 to go back to main menu: ").lower()
        if (prompt == '0'):
            flag = False
        else:
            flag = search_input(prompt, address_list)


def look_for_collocations(address_list):

    print("Look Up  Address")
    flag = True
    while flag:
        prompt = input("Please enter a two-word phrase: ").lower()
        splitted_prompt = prompt.split()
        user_input = ' '.join(splitted_prompt)

        if (len(splitted_prompt) == 2):
            token_list = []
            for key, value in address_list.items():
                token_list += value.tokens
            temp = ' '.join(token_list)

            vocab = len(set(temp))
            hg = temp.count(user_input) / vocab
            print("p(",user_input,") = ", hg)
            h = temp.count(splitted_prompt[0]) / vocab
            print("p(",splitted_prompt[0],") = ", h)
            g = temp.count(splitted_prompt[1]) / vocab
            print('p(',splitted_prompt[1],') = ', g)
            print(h,g, hg)
            if h*g > 0 and hg >0:
                pmi = math.log2(hg / (h * g))
            else:
                pmi=0
            print('pmi = ', pmi)
            flag = False
        else:
            flag = True


def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):
    bigram_finder = BigramCollocationFinder.from_words(words)
    bigrams = bigram_finder.nbest(score_fn, n)
    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)
                if type(ngram) == tuple])


def search_input(prompt, address_list):
    result = [k for k, v in address_list.items() if k[0] == prompt]
    if len(result) > 0 :
        for key in result:
            print(key)
        flag2 = True
        while flag2:
            prompt2 = input("Please select a year: ")
            for index in result :
                if index[1] == prompt2:
                    print("\n******************************************************************************************")
                    print("Year:", address_list[index].year)
                    print("President:", address_list[index].president)
                    print("Length in words:", address_list[index].orig_tokens_length)
                    print("Readability =", address_list[index].read_score, "which is level", address_list[index].read_rate)
                    print("Sentiment analysis:", address_list[index].sentiment)
                    print("\n First few lines:")
                    disp_text = (address_list[index].orig_text).split('.')
                    print(" ".join(disp_text[:3]))

                    return False

    else:
        return True

def get_user_input():
    # Get User input and exit if input is '!'
    opt = input("Please enter your selection: ")
    if opt == '9':
        print("Your Selected Option: Quit\n")
        print("Quiting")
        quit()
    else:
        return opt


def preprocess(content_list):
    count=0
    address_dict = {}
    toolbar_width = 40
    output = sys.stdout
    output.write("[%s]" % (" " * toolbar_width))
    output.flush()
    output.write("\b" * (toolbar_width + 1))  # return to start of line, after '['

    for key, value in content_list.items():
        count+=1
        file_name_list = re.split("-|.txt|!", key)
        file_name_list.pop(2)
        year = file_name_list[0]
        president = file_name_list[1]
        orig_text = value
        tokens = word_tokenize(value)
        orig_tokens_length = len(tokens)
        tokens_lower = [t.lower() for t in tokens]
        tokens_t = [t for t in tokens_lower if t.isalpha() and
                    t not in stopwords.words('english') ]
        fdist = FreqDist(tokens_t)
        most_common_25 =fdist.most_common(25)
        address = Address(year, president,orig_text,orig_tokens_length,tokens_t,most_common_25)
        address.compute_readability()
        key_tuple = ((address.president).lower(), address.year)
        address_dict[key_tuple] = address
        output.write('-')

        output.flush()

    output.write("]\n")  # this ends the progress bar
    return address_dict


# ==============================
def read_files():
    # setup toolbar
    sys.stdout.write("]\n")  # this ends the progress bar
    # assign directory
    if not path.exists("address.pickle"):
        print("Initializing! Please Wait...")
        directory = 'data/inaugural'
        content_list = {}
        # iterate over files in that directory
        for filename in os.listdir(directory):
            if filename != 'README':
                file_path = os.path.join(directory, filename)
                with open(file_path, encoding="utf8", errors='ignore') as f:
                    content_list[filename] = f.read()
        address_dictionary = preprocess(content_list)

        pickle.dump(address_dictionary, open("address.pickle", "wb"))

    pickledAddress = pickle.load(open("address.pickle", "rb"))
    while True:
        text_analyzer(pickledAddress)



if __name__ == '__main__':
    read_files()

